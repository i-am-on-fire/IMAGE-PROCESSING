{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3a73fe",
   "metadata": {
    "id": "6b3a73fe",
    "outputId": "0c67b229-5df9-4e5c-b50e-6703ed41b06e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix , classification_report \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import cv2, os\n",
    "from keras.layers import Flatten\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.layers import Conv2D,MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2fe184",
   "metadata": {
    "id": "8f2fe184"
   },
   "outputs": [],
   "source": [
    "train_dir = r\"dataset/Binarydataset/train_model\" \n",
    "test_dir = r\"dataset/Binarydataset/test_model\"\n",
    "\n",
    "SEED = 12\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "#FINE_TUNING_EPOCHS = 30\n",
    "LR = 0.001\n",
    "NUM_CLASSES = 8\n",
    "EARLY_STOPPING_CRITERIA=3\n",
    "CLASS_LABELS  = ['Amusement', 'Anger', 'Awe', 'Contentment', 'Disgust', 'Excitement', 'Fear', 'Sadness']\n",
    "CLASS_LABELS_EMOJIS = [\"ðŸ¥³\", \"ðŸ˜¡\", \"ðŸ˜¯\", \"ðŸ˜Œ\", \"ðŸ¤¢\" ,\"ðŸ¤©\", \"ðŸ˜±\" , \"ðŸ˜”\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b0a31c",
   "metadata": {
    "id": "18b0a31c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18009 images belonging to 2 classes.\n",
      "Found 3277 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "preprocess_fun = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.05,\n",
    "                                   rotation_range= 10,\n",
    "                                   rescale = 1./255,\n",
    "                                   validation_split = 0,\n",
    "                                   preprocessing_function=preprocess_fun\n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0,\n",
    "                                  preprocessing_function=preprocess_fun)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset = \"training\",\n",
    "                                                    seed = 12\n",
    "                                                   )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = False , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = 12\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32615ef9",
   "metadata": {
    "id": "32615ef9"
   },
   "outputs": [],
   "source": [
    "def classifier(inputs):\n",
    "    x = Conv2D(96,(11,11), strides = (4,4) , input_shape = (224,224,3), activation = 'relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides= (2,2))(x)\n",
    "    x = tf.keras.layers.Normalization()(x)\n",
    "    x = Conv2D(256,(5,5), strides = (2,2), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides= (2,2))(x)\n",
    "    x = tf.keras.layers.Normalization()(x)\n",
    "    x = Conv2D(96,(3,3), strides = (1,1), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides= (2,2))(x)\n",
    "    x = tf.keras.layers.Normalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(2, activation = 'softmax')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def final_model(inputs):\n",
    "    classification_output = classifier(inputs)\n",
    "    \n",
    "    return classification_output\n",
    "\n",
    "def define_compile_model():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(224,224,3))\n",
    "    classification_output = final_model(inputs) \n",
    "    model = tf.keras.Model(inputs= inputs, outputs= classification_output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4397984a",
   "metadata": {
    "id": "4397984a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 26, 26, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " normalization_3 (Normalizat  (None, 26, 26, 96)       193       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " normalization_4 (Normalizat  (None, 5, 5, 256)        513       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 96)          221280    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 1, 1, 96)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " normalization_5 (Normalizat  (None, 1, 1, 96)         193       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              397312    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,058,597\n",
      "Trainable params: 18,057,698\n",
      "Non-trainable params: 899\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_compile_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e842db5f",
   "metadata": {
    "id": "e842db5f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('Binary-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5', verbose=1, \n",
    "                             monitor='val_accuracy',save_best_only=True, mode='auto') \n",
    "# earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351079d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.7074\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73055, saving model to Binary-001-0.707369-0.730546.h5\n",
      "282/282 [==============================] - 372s 1s/step - loss: 0.5811 - accuracy: 0.7074 - val_loss: 0.5355 - val_accuracy: 0.7305\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.7309\n",
      "Epoch 2: val_accuracy improved from 0.73055 to 0.74062, saving model to Binary-002-0.730912-0.740616.h5\n",
      "282/282 [==============================] - 262s 931ms/step - loss: 0.5388 - accuracy: 0.7309 - val_loss: 0.5194 - val_accuracy: 0.7406\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7370\n",
      "Epoch 3: val_accuracy improved from 0.74062 to 0.74428, saving model to Binary-003-0.737020-0.744278.h5\n",
      "282/282 [==============================] - 271s 960ms/step - loss: 0.5298 - accuracy: 0.7370 - val_loss: 0.5158 - val_accuracy: 0.7443\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.7411\n",
      "Epoch 4: val_accuracy did not improve from 0.74428\n",
      "282/282 [==============================] - 260s 921ms/step - loss: 0.5226 - accuracy: 0.7411 - val_loss: 0.5298 - val_accuracy: 0.7235\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.7467\n",
      "Epoch 5: val_accuracy did not improve from 0.74428\n",
      "282/282 [==============================] - 269s 955ms/step - loss: 0.5181 - accuracy: 0.7467 - val_loss: 0.5087 - val_accuracy: 0.7434\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.7463\n",
      "Epoch 6: val_accuracy improved from 0.74428 to 0.74611, saving model to Binary-006-0.746349-0.746109.h5\n",
      "282/282 [==============================] - 288s 1s/step - loss: 0.5158 - accuracy: 0.7463 - val_loss: 0.5061 - val_accuracy: 0.7461\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5105 - accuracy: 0.7485\n",
      "Epoch 7: val_accuracy did not improve from 0.74611\n",
      "282/282 [==============================] - 434s 2s/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5137 - val_accuracy: 0.7397\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7502\n",
      "Epoch 8: val_accuracy did not improve from 0.74611\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.5072 - accuracy: 0.7502 - val_loss: 0.5118 - val_accuracy: 0.7376\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.7526\n",
      "Epoch 9: val_accuracy did not improve from 0.74611\n",
      "282/282 [==============================] - 414s 1s/step - loss: 0.5055 - accuracy: 0.7526 - val_loss: 0.5041 - val_accuracy: 0.7431\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.7531\n",
      "Epoch 10: val_accuracy improved from 0.74611 to 0.75008, saving model to Binary-010-0.753068-0.750076.h5\n",
      "282/282 [==============================] - 421s 1s/step - loss: 0.5023 - accuracy: 0.7531 - val_loss: 0.5057 - val_accuracy: 0.7501\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.7535\n",
      "Epoch 11: val_accuracy improved from 0.75008 to 0.75252, saving model to Binary-011-0.753457-0.752518.h5\n",
      "282/282 [==============================] - 414s 1s/step - loss: 0.5004 - accuracy: 0.7535 - val_loss: 0.4955 - val_accuracy: 0.7525\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.7556\n",
      "Epoch 12: val_accuracy did not improve from 0.75252\n",
      "282/282 [==============================] - 418s 1s/step - loss: 0.4957 - accuracy: 0.7556 - val_loss: 0.4965 - val_accuracy: 0.7504\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.7563\n",
      "Epoch 13: val_accuracy did not improve from 0.75252\n",
      "282/282 [==============================] - 420s 1s/step - loss: 0.4948 - accuracy: 0.7563 - val_loss: 0.4956 - val_accuracy: 0.7464\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.7584\n",
      "Epoch 14: val_accuracy did not improve from 0.75252\n",
      "282/282 [==============================] - 418s 1s/step - loss: 0.4920 - accuracy: 0.7584 - val_loss: 0.5020 - val_accuracy: 0.7418\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.7598\n",
      "Epoch 15: val_accuracy did not improve from 0.75252\n",
      "282/282 [==============================] - 426s 2s/step - loss: 0.4882 - accuracy: 0.7598 - val_loss: 0.4993 - val_accuracy: 0.7489\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.7585\n",
      "Epoch 16: val_accuracy did not improve from 0.75252\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.4883 - accuracy: 0.7585 - val_loss: 0.5079 - val_accuracy: 0.7394\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.7633\n",
      "Epoch 17: val_accuracy did not improve from 0.75252\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.4837 - accuracy: 0.7633 - val_loss: 0.5223 - val_accuracy: 0.7421\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.7613\n",
      "Epoch 18: val_accuracy did not improve from 0.75252\n",
      "282/282 [==============================] - 419s 1s/step - loss: 0.4812 - accuracy: 0.7613 - val_loss: 0.4988 - val_accuracy: 0.7525\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.7627\n",
      "Epoch 19: val_accuracy improved from 0.75252 to 0.75587, saving model to Binary-019-0.762730-0.755874.h5\n",
      "282/282 [==============================] - 420s 1s/step - loss: 0.4791 - accuracy: 0.7627 - val_loss: 0.4940 - val_accuracy: 0.7559\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.7655\n",
      "Epoch 20: val_accuracy did not improve from 0.75587\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.4770 - accuracy: 0.7655 - val_loss: 0.4937 - val_accuracy: 0.7519\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.7676\n",
      "Epoch 21: val_accuracy improved from 0.75587 to 0.75618, saving model to Binary-021-0.767616-0.756179.h5\n",
      "282/282 [==============================] - 399s 1s/step - loss: 0.4744 - accuracy: 0.7676 - val_loss: 0.4931 - val_accuracy: 0.7562\n",
      "Epoch 22/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.7694\n",
      "Epoch 22: val_accuracy did not improve from 0.75618\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.4718 - accuracy: 0.7694 - val_loss: 0.4960 - val_accuracy: 0.7562\n",
      "Epoch 23/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.7728\n",
      "Epoch 23: val_accuracy did not improve from 0.75618\n",
      "282/282 [==============================] - 420s 1s/step - loss: 0.4663 - accuracy: 0.7728 - val_loss: 0.5080 - val_accuracy: 0.7458\n",
      "Epoch 24/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.7723\n",
      "Epoch 24: val_accuracy did not improve from 0.75618\n",
      "282/282 [==============================] - 391s 1s/step - loss: 0.4657 - accuracy: 0.7723 - val_loss: 0.4899 - val_accuracy: 0.7547\n",
      "Epoch 25/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.7736\n",
      "Epoch 25: val_accuracy did not improve from 0.75618\n",
      "282/282 [==============================] - 411s 1s/step - loss: 0.4635 - accuracy: 0.7736 - val_loss: 0.5058 - val_accuracy: 0.7510\n",
      "Epoch 26/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.7723\n",
      "Epoch 26: val_accuracy did not improve from 0.75618\n",
      "282/282 [==============================] - 423s 2s/step - loss: 0.4610 - accuracy: 0.7723 - val_loss: 0.4878 - val_accuracy: 0.7556\n",
      "Epoch 27/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.7776\n",
      "Epoch 27: val_accuracy did not improve from 0.75618\n",
      "282/282 [==============================] - 413s 1s/step - loss: 0.4564 - accuracy: 0.7776 - val_loss: 0.4884 - val_accuracy: 0.7513\n",
      "Epoch 28/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.7752\n",
      "Epoch 28: val_accuracy did not improve from 0.75618\n",
      "282/282 [==============================] - 421s 1s/step - loss: 0.4561 - accuracy: 0.7752 - val_loss: 0.5084 - val_accuracy: 0.7547\n",
      "Epoch 29/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.7815\n",
      "Epoch 29: val_accuracy improved from 0.75618 to 0.75679, saving model to Binary-029-0.781498-0.756790.h5\n",
      "282/282 [==============================] - 428s 2s/step - loss: 0.4551 - accuracy: 0.7815 - val_loss: 0.4861 - val_accuracy: 0.7568\n",
      "Epoch 30/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.7818\n",
      "Epoch 30: val_accuracy improved from 0.75679 to 0.75893, saving model to Binary-030-0.781831-0.758926.h5\n",
      "282/282 [==============================] - 415s 1s/step - loss: 0.4475 - accuracy: 0.7818 - val_loss: 0.4905 - val_accuracy: 0.7589\n",
      "Epoch 31/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.7851\n",
      "Epoch 31: val_accuracy did not improve from 0.75893\n",
      "282/282 [==============================] - 424s 2s/step - loss: 0.4467 - accuracy: 0.7851 - val_loss: 0.4958 - val_accuracy: 0.7556\n",
      "Epoch 32/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.7889\n",
      "Epoch 32: val_accuracy did not improve from 0.75893\n",
      "282/282 [==============================] - 418s 1s/step - loss: 0.4405 - accuracy: 0.7889 - val_loss: 0.4922 - val_accuracy: 0.7516\n",
      "Epoch 33/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.7909\n",
      "Epoch 33: val_accuracy did not improve from 0.75893\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.4365 - accuracy: 0.7909 - val_loss: 0.5256 - val_accuracy: 0.7428\n",
      "Epoch 34/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.7899\n",
      "Epoch 34: val_accuracy did not improve from 0.75893\n",
      "282/282 [==============================] - 408s 1s/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5334 - val_accuracy: 0.7553\n",
      "Epoch 35/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.7924\n",
      "Epoch 35: val_accuracy did not improve from 0.75893\n",
      "282/282 [==============================] - 409s 1s/step - loss: 0.4341 - accuracy: 0.7924 - val_loss: 0.4952 - val_accuracy: 0.7577\n",
      "Epoch 36/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.7949\n",
      "Epoch 36: val_accuracy did not improve from 0.75893\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.4260 - accuracy: 0.7949 - val_loss: 0.5096 - val_accuracy: 0.7531\n",
      "Epoch 37/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.7960\n",
      "Epoch 37: val_accuracy did not improve from 0.75893\n",
      "282/282 [==============================] - 420s 1s/step - loss: 0.4264 - accuracy: 0.7960 - val_loss: 0.4906 - val_accuracy: 0.7522\n",
      "Epoch 38/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.7979\n",
      "Epoch 38: val_accuracy improved from 0.75893 to 0.75954, saving model to Binary-038-0.797934-0.759536.h5\n",
      "282/282 [==============================] - 424s 2s/step - loss: 0.4210 - accuracy: 0.7979 - val_loss: 0.5055 - val_accuracy: 0.7595\n",
      "Epoch 39/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.8022\n",
      "Epoch 39: val_accuracy improved from 0.75954 to 0.76289, saving model to Binary-039-0.802210-0.762893.h5\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.4180 - accuracy: 0.8022 - val_loss: 0.4992 - val_accuracy: 0.7629\n",
      "Epoch 40/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.8025\n",
      "Epoch 40: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 415s 1s/step - loss: 0.4117 - accuracy: 0.8025 - val_loss: 0.5213 - val_accuracy: 0.7540\n",
      "Epoch 41/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8064\n",
      "Epoch 41: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 424s 2s/step - loss: 0.4077 - accuracy: 0.8064 - val_loss: 0.5107 - val_accuracy: 0.7556\n",
      "Epoch 42/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.8058\n",
      "Epoch 42: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.4078 - accuracy: 0.8058 - val_loss: 0.5111 - val_accuracy: 0.7553\n",
      "Epoch 43/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8086\n",
      "Epoch 43: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.4029 - accuracy: 0.8086 - val_loss: 0.4930 - val_accuracy: 0.7620\n",
      "Epoch 44/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8073\n",
      "Epoch 44: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 421s 1s/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7577\n",
      "Epoch 45/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8157\n",
      "Epoch 45: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 416s 1s/step - loss: 0.3978 - accuracy: 0.8157 - val_loss: 0.5088 - val_accuracy: 0.7498\n",
      "Epoch 46/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.8161\n",
      "Epoch 46: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 421s 1s/step - loss: 0.3929 - accuracy: 0.8161 - val_loss: 0.5101 - val_accuracy: 0.7403\n",
      "Epoch 47/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8181\n",
      "Epoch 47: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 413s 1s/step - loss: 0.3881 - accuracy: 0.8181 - val_loss: 0.5647 - val_accuracy: 0.7571\n",
      "Epoch 48/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8240\n",
      "Epoch 48: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 414s 1s/step - loss: 0.3814 - accuracy: 0.8240 - val_loss: 0.5208 - val_accuracy: 0.7510\n",
      "Epoch 49/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8186\n",
      "Epoch 49: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 413s 1s/step - loss: 0.3861 - accuracy: 0.8186 - val_loss: 0.5195 - val_accuracy: 0.7583\n",
      "Epoch 50/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3704 - accuracy: 0.8279\n",
      "Epoch 50: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 407s 1s/step - loss: 0.3704 - accuracy: 0.8279 - val_loss: 0.5382 - val_accuracy: 0.7373\n",
      "Epoch 51/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8314\n",
      "Epoch 51: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.3695 - accuracy: 0.8314 - val_loss: 0.5141 - val_accuracy: 0.7556\n",
      "Epoch 52/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8284\n",
      "Epoch 52: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 417s 1s/step - loss: 0.3676 - accuracy: 0.8284 - val_loss: 0.5340 - val_accuracy: 0.7605\n",
      "Epoch 53/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.8345\n",
      "Epoch 53: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 436s 2s/step - loss: 0.3618 - accuracy: 0.8345 - val_loss: 0.5416 - val_accuracy: 0.7513\n",
      "Epoch 54/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8315\n",
      "Epoch 54: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 416s 1s/step - loss: 0.3657 - accuracy: 0.8315 - val_loss: 0.5528 - val_accuracy: 0.7516\n",
      "Epoch 55/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.8365\n",
      "Epoch 55: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 419s 1s/step - loss: 0.3573 - accuracy: 0.8365 - val_loss: 0.5369 - val_accuracy: 0.7568\n",
      "Epoch 56/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.8360\n",
      "Epoch 56: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.3565 - accuracy: 0.8360 - val_loss: 0.5343 - val_accuracy: 0.7583\n",
      "Epoch 57/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.8426\n",
      "Epoch 57: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 415s 1s/step - loss: 0.3450 - accuracy: 0.8426 - val_loss: 0.5482 - val_accuracy: 0.7492\n",
      "Epoch 58/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8402\n",
      "Epoch 58: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 416s 1s/step - loss: 0.3473 - accuracy: 0.8402 - val_loss: 0.5420 - val_accuracy: 0.7629\n",
      "Epoch 59/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8422\n",
      "Epoch 59: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.3494 - accuracy: 0.8422 - val_loss: 0.5750 - val_accuracy: 0.7305\n",
      "Epoch 60/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3376 - accuracy: 0.8493\n",
      "Epoch 60: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 418s 1s/step - loss: 0.3376 - accuracy: 0.8493 - val_loss: 0.5428 - val_accuracy: 0.7351\n",
      "Epoch 61/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.8472\n",
      "Epoch 61: val_accuracy did not improve from 0.76289\n",
      "282/282 [==============================] - 423s 1s/step - loss: 0.3347 - accuracy: 0.8472 - val_loss: 0.5488 - val_accuracy: 0.7568\n",
      "Epoch 62/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.8520\n",
      "Epoch 62: val_accuracy improved from 0.76289 to 0.76747, saving model to Binary-062-0.852018-0.767470.h5\n",
      "282/282 [==============================] - 417s 1s/step - loss: 0.3317 - accuracy: 0.8520 - val_loss: 0.5680 - val_accuracy: 0.7675\n",
      "Epoch 63/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3289 - accuracy: 0.8513\n",
      "Epoch 63: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 410s 1s/step - loss: 0.3289 - accuracy: 0.8513 - val_loss: 0.5439 - val_accuracy: 0.7531\n",
      "Epoch 64/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.8521\n",
      "Epoch 64: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 418s 1s/step - loss: 0.3253 - accuracy: 0.8521 - val_loss: 0.5504 - val_accuracy: 0.7531\n",
      "Epoch 65/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.8582\n",
      "Epoch 65: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 414s 1s/step - loss: 0.3180 - accuracy: 0.8582 - val_loss: 0.5770 - val_accuracy: 0.7455\n",
      "Epoch 66/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8620\n",
      "Epoch 66: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 432s 2s/step - loss: 0.3123 - accuracy: 0.8620 - val_loss: 0.5621 - val_accuracy: 0.7537\n",
      "Epoch 67/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8631\n",
      "Epoch 67: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 416s 1s/step - loss: 0.3068 - accuracy: 0.8631 - val_loss: 0.5937 - val_accuracy: 0.7537\n",
      "Epoch 68/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.8625\n",
      "Epoch 68: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 415s 1s/step - loss: 0.3127 - accuracy: 0.8625 - val_loss: 0.6129 - val_accuracy: 0.7605\n",
      "Epoch 69/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.8691\n",
      "Epoch 69: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 410s 1s/step - loss: 0.2960 - accuracy: 0.8691 - val_loss: 0.5943 - val_accuracy: 0.7449\n",
      "Epoch 70/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3005 - accuracy: 0.8659\n",
      "Epoch 70: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 411s 1s/step - loss: 0.3005 - accuracy: 0.8659 - val_loss: 0.5840 - val_accuracy: 0.7492\n",
      "Epoch 71/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.8672\n",
      "Epoch 71: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.2972 - accuracy: 0.8672 - val_loss: 0.6175 - val_accuracy: 0.7547\n",
      "Epoch 72/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2939 - accuracy: 0.8693\n",
      "Epoch 72: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 420s 1s/step - loss: 0.2939 - accuracy: 0.8693 - val_loss: 0.6220 - val_accuracy: 0.7580\n",
      "Epoch 73/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.8740\n",
      "Epoch 73: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 420s 1s/step - loss: 0.2900 - accuracy: 0.8740 - val_loss: 0.6166 - val_accuracy: 0.7598\n",
      "Epoch 74/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.8774\n",
      "Epoch 74: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 421s 1s/step - loss: 0.2819 - accuracy: 0.8774 - val_loss: 0.6187 - val_accuracy: 0.7501\n",
      "Epoch 75/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.8798\n",
      "Epoch 75: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 420s 1s/step - loss: 0.2770 - accuracy: 0.8798 - val_loss: 0.6270 - val_accuracy: 0.7504\n",
      "Epoch 76/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.8809\n",
      "Epoch 76: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 415s 1s/step - loss: 0.2740 - accuracy: 0.8809 - val_loss: 0.6671 - val_accuracy: 0.7510\n",
      "Epoch 77/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8830\n",
      "Epoch 77: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 296s 1s/step - loss: 0.2717 - accuracy: 0.8830 - val_loss: 0.6469 - val_accuracy: 0.7513\n",
      "Epoch 78/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.8804\n",
      "Epoch 78: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 266s 944ms/step - loss: 0.2729 - accuracy: 0.8804 - val_loss: 0.6312 - val_accuracy: 0.7559\n",
      "Epoch 79/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.8819\n",
      "Epoch 79: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 264s 937ms/step - loss: 0.2733 - accuracy: 0.8819 - val_loss: 0.6161 - val_accuracy: 0.7525\n",
      "Epoch 80/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.8874\n",
      "Epoch 80: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 257s 910ms/step - loss: 0.2591 - accuracy: 0.8874 - val_loss: 0.6392 - val_accuracy: 0.7519\n",
      "Epoch 81/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.8834\n",
      "Epoch 81: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 271s 960ms/step - loss: 0.2670 - accuracy: 0.8834 - val_loss: 0.6163 - val_accuracy: 0.7376\n",
      "Epoch 82/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.8868\n",
      "Epoch 82: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 268s 949ms/step - loss: 0.2579 - accuracy: 0.8868 - val_loss: 0.6657 - val_accuracy: 0.7525\n",
      "Epoch 83/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2512 - accuracy: 0.8897\n",
      "Epoch 83: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 259s 918ms/step - loss: 0.2512 - accuracy: 0.8897 - val_loss: 0.6753 - val_accuracy: 0.7510\n",
      "Epoch 84/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.8888\n",
      "Epoch 84: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 257s 912ms/step - loss: 0.2543 - accuracy: 0.8888 - val_loss: 0.7087 - val_accuracy: 0.7598\n",
      "Epoch 85/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2445 - accuracy: 0.8948\n",
      "Epoch 85: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 265s 939ms/step - loss: 0.2445 - accuracy: 0.8948 - val_loss: 0.6989 - val_accuracy: 0.7562\n",
      "Epoch 86/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.8966\n",
      "Epoch 86: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 316s 1s/step - loss: 0.2436 - accuracy: 0.8966 - val_loss: 0.6682 - val_accuracy: 0.7583\n",
      "Epoch 87/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.8931\n",
      "Epoch 87: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 412s 1s/step - loss: 0.2474 - accuracy: 0.8931 - val_loss: 0.6747 - val_accuracy: 0.7598\n",
      "Epoch 88/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.8956\n",
      "Epoch 88: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 417s 1s/step - loss: 0.2393 - accuracy: 0.8956 - val_loss: 0.6733 - val_accuracy: 0.7388\n",
      "Epoch 89/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.8983\n",
      "Epoch 89: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 410s 1s/step - loss: 0.2366 - accuracy: 0.8983 - val_loss: 0.6663 - val_accuracy: 0.7421\n",
      "Epoch 90/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.8982\n",
      "Epoch 90: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 412s 1s/step - loss: 0.2370 - accuracy: 0.8982 - val_loss: 0.6907 - val_accuracy: 0.7534\n",
      "Epoch 91/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9028\n",
      "Epoch 91: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 418s 1s/step - loss: 0.2289 - accuracy: 0.9028 - val_loss: 0.7499 - val_accuracy: 0.7510\n",
      "Epoch 92/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9028\n",
      "Epoch 92: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 424s 2s/step - loss: 0.2307 - accuracy: 0.9028 - val_loss: 0.6986 - val_accuracy: 0.7568\n",
      "Epoch 93/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9064\n",
      "Epoch 93: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 410s 1s/step - loss: 0.2238 - accuracy: 0.9064 - val_loss: 0.6974 - val_accuracy: 0.7510\n",
      "Epoch 94/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9053\n",
      "Epoch 94: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 439s 2s/step - loss: 0.2236 - accuracy: 0.9053 - val_loss: 0.7142 - val_accuracy: 0.7543\n",
      "Epoch 95/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9052\n",
      "Epoch 95: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 414s 1s/step - loss: 0.2200 - accuracy: 0.9052 - val_loss: 0.7229 - val_accuracy: 0.7516\n",
      "Epoch 96/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9104\n",
      "Epoch 96: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 427s 2s/step - loss: 0.2122 - accuracy: 0.9104 - val_loss: 0.7173 - val_accuracy: 0.7516\n",
      "Epoch 97/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9064\n",
      "Epoch 97: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 417s 1s/step - loss: 0.2189 - accuracy: 0.9064 - val_loss: 0.7252 - val_accuracy: 0.7498\n",
      "Epoch 98/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.9083\n",
      "Epoch 98: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 418s 1s/step - loss: 0.2110 - accuracy: 0.9083 - val_loss: 0.8274 - val_accuracy: 0.7504\n",
      "Epoch 99/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.9076\n",
      "Epoch 99: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 404s 1s/step - loss: 0.2158 - accuracy: 0.9076 - val_loss: 0.6983 - val_accuracy: 0.7540\n",
      "Epoch 100/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9154\n",
      "Epoch 100: val_accuracy did not improve from 0.76747\n",
      "282/282 [==============================] - 422s 1s/step - loss: 0.2014 - accuracy: 0.9154 - val_loss: 0.7366 - val_accuracy: 0.7452\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, batch_size = BATCH_SIZE,\n",
    "                   epochs= 100, validation_data= test_generator,\n",
    "                   validation_batch_size = BATCH_SIZE, callbacks= [checkpoint]\n",
    "                   )\n",
    "\n",
    "history = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd16b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model somewhere\n"
     ]
    }
   ],
   "source": [
    "#saving the  model to be used later\n",
    "fer_json = model.to_json()\n",
    "with open(\"Binary.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "#model.save_weights(\"VGG16_512.h5\") #make sure to rename this file after each 100 epochs\n",
    "print(\"Saved model somewhere\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "BinaryClassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
